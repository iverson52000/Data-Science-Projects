{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jan  8 09:57:43 2019\n",
    "\n",
    "@author: albhsu\n",
    "\"\"\"\n",
    "\n",
    "#####This is a on-job self-development project. Only the sample of my code is provided#####\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc, roc_curve, classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('PG_test.csv')\n",
    "data.head()\n",
    "data.info()\n",
    "\n",
    "# Check if any missing data\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split datset into training and testing set\n",
    "data['is_train'] = np.random.uniform(0, 1, len(data)) <= .75\n",
    "train, test = data[data['is_train']==True], data[data['is_train']==False]\n",
    "features = data.columns[6:67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Logistic Regression model\n",
    "y_train = pd.factorize(train['PGDEF'])[0]\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='ovr')\n",
    "clf.fit(train[features], y_train)\n",
    "y_pred = clf.predict(test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier score and Confusion Matrix\n",
    "clf.score(test[features], test['PGDEF'])\n",
    "cm = metrics.confusion_matrix(test['PGDEF'], y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance\n",
    "importance = pd.DataFrame(index = features, data = clf.feature_importances_, columns = ['importance'])\n",
    "importance.sort_values(by = 'importance', ascending = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot feature importance\n",
    "ax = importance[-5:].plot.barh()\n",
    "y_pos = np.arange(len(features))\n",
    "plt.barh(y_pos, clf.coef_.ravel())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way to get Confusion matrix\n",
    "pd.crosstab(test['y'], y_pred)\n",
    "\n",
    "#Classification report\n",
    "target_names = ['0', '1']\n",
    "y_pred = clf.predict(test[features])\n",
    "y_actual = test['PGDEF']\n",
    "print(classification_report(y_actual, y_pred, target_names=target_names))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_pred, y_actual, pos_label=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
